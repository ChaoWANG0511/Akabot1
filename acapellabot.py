"""
Acapella extraction with a CNN

Typical usage:
    python acapellabot.py song.wav
    => Extracts acapella from <song.wav> to <song (Acapella Attempt).wav> using default weights   åˆ†ç¦»

    python acapellabot.py --data input_folder --batch 32 --weights new_model_iteration.h5
    => Trains a new model based on song/acapella pairs in the folder <input_folder>   è®­ç»ƒ
       and saves weights to <new_model_iteration.h5> once complete.
       See data.py for data specifications.
"""

import argparse
import random
import string
import os

import numpy as np
import console
import conversion
from data import Data
from Model import creat_model
from unet import apply_unet
from lstm import blstm
from keras.models import model_from_json

class AcapellaBot:
    # å®šä¹‰model
    def __init__(self):

        #m = creat_model()
        #m = apply_unet()
        m = blstm()
        console.log("Model has", m.count_params(), "params")

        m.compile(loss='mean_squared_error', optimizer='adam')

        self.model = m
        # need to know so that we can avoid rounding errors with spectrogram
        # this should represent how much the input gets downscaled
        # in the middle of the network
        self.peakDownscaleFactor = 64

    # è®­ç»ƒéªŒè¯model.fit, ç»™data, epochs, batch, æ˜¯å¦å­˜æƒé‡
    def train(self, data, epochs, batch=8):
        xTrain, yTrain = data.train()
        xValid, yValid = data.valid()
        xTrain = np.squeeze(xTrain)
        yTrain = np.squeeze(yTrain)
        xValid = np.squeeze(xValid)
        yValid = np.squeeze(yValid)

        console.log("Training for", epochs, "epochs on", len(xTrain), "examples")   # æ‰“å°

        self.model.fit(xTrain, yTrain, batch_size=batch, epochs=epochs, validation_data=(xValid, yValid))
        self.model.summary()

        console.notify(str(epochs) + " Epochs Complete!", "Training on", data.inPath, "with size", batch)

        weightPath = ''.join(random.choice(string.digits) for _ in range(16)) + ".h5"
        console.log("Saving intermediate weights to", weightPath)
        self.saveWeights(weightPath)


    def saveWeights(self, path):
        self.model.save_weights(path, overwrite=True)
    def loadWeights(self, path):
        self.model.load_weights(path,by_name=True)
        #json_string = self.model.to_json()
        #self.model = model_from_json(json_string)



    # é¢„æµ‹modelï¼Œ æ•°æ®å¤„ç†stft
    def isolateVocals(self, path, fftWindowSize, phaseIterations=10):
        # audio stft å¾—å¹…å€¼
        console.log("Attempting to isolate vocals from", path)
        audio, sampleRate = conversion.loadAudioFile(path)   # éŸ³é¢‘çš„ä¿¡å·å€¼float ndarray
        spectrogram, phase = conversion.audioFileToSpectrogram(audio, fftWindowSize=fftWindowSize)     # stftå¾—åˆ°çš„çŸ©é˜µçš„å¹…å€¼å’Œç›¸ä½
        console.log("Retrieved spectrogram; processing...")

        # å¹…å€¼ è¿›æ¨¡åž‹ å¾—å¹…å€¼
        # newSpectrogram = self.model.predict(conversion.expandToGrid(spectrogram, self.peakDownscaleFactor)[np.newaxis, :, :, np.newaxis])[0][:spectrogram.shape[0], :spectrogram.shape[1]]
        expandedSpectrogram = conversion.expandToGrid(spectrogram, self.peakDownscaleFactor)   # å¹…å€¼æ”¾å¤§ä¸€äº›byåŠ 0ï¼Œä¸ºäº†èƒ½æ•´é™¤peakDownscaleFactor
        #expandedSpectrogramWithBatchAndChannels = expandedSpectrogram[np.newaxis, :, :, np.newaxis]  # ç¬¬ä¸€ç»´åŠ batchï¼Œç¬¬å››ç»´åŠ channel
        expandedSpectrogramWithBatchAndChannels = np.squeeze(expandedSpectrogramWithBatchAndChannels)
        predictedSpectrogramWithBatchAndChannels = self.model.predict(expandedSpectrogramWithBatchAndChannels)   # æ”¾å…¥modelåšé¢„æµ‹
        predictedSpectrogram = predictedSpectrogramWithBatchAndChannels[0, :, :, 0] # o /// o   # å–é¢„æµ‹ç»“æžœçš„ç¬¬0batchï¼Œç¬¬0channel,å³å†å˜å›žå¹…å€¼
        newSpectrogram = predictedSpectrogram[:spectrogram.shape[0], :spectrogram.shape[1]]    # å¹…å€¼ç¼©å°ä¸ºåŽŸæ¥çš„å°ºå¯¸
        console.log("Processed spectrogram; reconverting to audio")

        # å¹…å€¼åstftè½¬ä¸ºé˜¿å¡è´æ‹‰audioæ•°
        newAudio = conversion.spectrogramToAudioFile(newSpectrogram, fftWindowSize=fftWindowSize, phaseIterations=phaseIterations)   # phase?
        pathParts = os.path.split(path)
        fileNameParts = os.path.splitext(pathParts[1])
        outputFileNameBase = os.path.join(pathParts[0], fileNameParts[0] + "_acapella")
        console.log("Converted to audio; writing to", outputFileNameBase)

        # æ•°è½¬éŸ³ï¼Œå­˜
        conversion.saveAudioFile(newAudio, outputFileNameBase + ".wav", sampleRate)
        conversion.saveSpectrogram(newSpectrogram, outputFileNameBase + ".png")
        conversion.saveSpectrogram(spectrogram, os.path.join(pathParts[0], fileNameParts[0]) + ".png")
        console.log("Vocal isolation complete ðŸ‘Œ")


if __name__ == "__main__":
    # if data folder is specified, create a new data object and train on the data
    # if input audio is specified, infer on the input
    parser = argparse.ArgumentParser(description="Acapella extraction with a convolutional neural network")
    parser.add_argument("--fft", default=1536, type=int, help="Size of FFT windows")
    parser.add_argument("--data", default=None, type=str, help="Path containing training data")
    parser.add_argument("--split", default=0.9, type=float, help="Proportion of the data to train on")
    parser.add_argument("--epochs", default=1, type=int, help="Number of epochs to train.")
    parser.add_argument("--weights", default="weights.h5", type=str, help="h5 file to read/write weights to")
    parser.add_argument("--batch", default=8, type=int, help="Batch size for training")
    parser.add_argument("--phase", default=10, type=int, help="Phase iterations for reconstruction")
    parser.add_argument("--load", action='store_true', help="Load previous weights file before starting")
    parser.add_argument("files", nargs="*", default=[])

    args = parser.parse_args()

    acapellabot = AcapellaBot()

    # ç»™data: è®­ç»ƒ
    if len(args.files) == 0 and args.data:
        console.log("No files provided; attempting to train on " + args.data + "...")
        if args.load:
            console.h1("Loading Weights")
            acapellabot.loadWeights(args.weights)
        console.h1("Loading Data")
        data = Data(args.data, args.fft, args.split)   # è®­ç»ƒç”¨çš„dataè§data.pyä¸­çš„ç±»Data
        console.h1("Training Model")
        acapellabot.train(data, args.epochs, args.batch)
        acapellabot.saveWeights(args.weights)

    # ç»™files: é¢„æµ‹
    elif len(args.files) > 0:
        console.log("Weights provided; performing inference on " + str(args.files) + "...")
        console.h1("Loading weights")
        acapellabot.loadWeights(args.weights)
        for f in args.files:
            acapellabot.isolateVocals(f, args.fft, args.phase)

    else:
        console.error("Please provide data to train on (--data) or files to infer on")
