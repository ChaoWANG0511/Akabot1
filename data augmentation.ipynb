{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from keras.initializers import he_uniform\n",
    "from keras.backend import int_shape, squeeze\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Input, Reshape, Lambda\n",
    "from math import ceil\n",
    "from functools import partial\n",
    "from keras.backend import int_shape, squeeze\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 mixtures in the given path to train\n",
      "{\"055 - Angels In Amplifiers - I'm Alright\": [\"DSD100subset/Mixtures/Dev\\\\055 - Angels In Amplifiers - I'm Alright/mixture.wav\", \"DSD100subset/Sources/Dev\\\\055 - Angels In Amplifiers - I'm Alright/bass.wav\", \"DSD100subset/Sources/Dev\\\\055 - Angels In Amplifiers - I'm Alright/drums.wav\", \"DSD100subset/Sources/Dev\\\\055 - Angels In Amplifiers - I'm Alright/other.wav\", \"DSD100subset/Sources/Dev\\\\055 - Angels In Amplifiers - I'm Alright/vocals.wav\"], '081 - Patrick Talbot - Set Me Free': ['DSD100subset/Mixtures/Dev\\\\081 - Patrick Talbot - Set Me Free/mixture.wav', 'DSD100subset/Sources/Dev\\\\081 - Patrick Talbot - Set Me Free/bass.wav', 'DSD100subset/Sources/Dev\\\\081 - Patrick Talbot - Set Me Free/drums.wav', 'DSD100subset/Sources/Dev\\\\081 - Patrick Talbot - Set Me Free/other.wav', 'DSD100subset/Sources/Dev\\\\081 - Patrick Talbot - Set Me Free/vocals.wav']}\n"
     ]
    }
   ],
   "source": [
    "def listdirInMac(path):\n",
    "    os_list = os.listdir(path)\n",
    "    for item in os_list:\n",
    "        if item.startswith('.') and os.path.isfile(os.path.join(path, item)):\n",
    "            os_list.remove(item)\n",
    "    return os_list\n",
    "\n",
    "def traversalDir_FirstDir(path):\n",
    "    dict = {}\n",
    "    files = listdirInMac(path)\n",
    "    for file in files:\n",
    "        m = os.path.join(path, file)\n",
    "        h = os.path.split(m)\n",
    "        dict[h[1]] = []\n",
    "        song_wav = listdirInMac(m)\n",
    "        m = m + '/'\n",
    "        for track in song_wav:\n",
    "            value = os.path.join(m, track)\n",
    "            dict[h[1]].append(value)\n",
    "    return dict\n",
    "\n",
    "mix_path = traversalDir_FirstDir('DSD100subset/Mixtures/Dev')\n",
    "\n",
    "sou_path = traversalDir_FirstDir('DSD100subset/Sources/Dev')\n",
    "\n",
    "all_path = mix_path.copy()\n",
    "for key in all_path.keys():\n",
    "    all_path[key].extend(sou_path[key])\n",
    "\n",
    "print(\"%d mixtures in the given path to train\"%len(mix_path))\n",
    "print(all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAudioFile(filePath):\n",
    "    audio, sampleRate = librosa.load(filePath, sr = 44100)  # Load an audio file as a floating point time series， 默认采样率sr=22050\n",
    "    return audio, sampleRate\n",
    "\n",
    "# Return a 2d numpy array of the spectrogram\n",
    "def audioFileToSpectrogram(audioFile, fftWindowSize = 1024):\n",
    "    # time resolution N/fs=1024/44100=23ms\n",
    "    spectrogram = librosa.stft(audioFile, fftWindowSize)   # 返回复数值矩阵D , STFT矩阵D中的行数是（1 + 第二个参数一般2的幂n_fft / 2）\n",
    "    phase = np.angle(spectrogram)\n",
    "    amplitude = np.log1p(np.abs(spectrogram))   # np.abs(D[f, t]) is the magnitude of frequency bin f at frame帧 t， loge(1+ )\n",
    "    return amplitude, phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "频谱矩阵做random time stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# audio/spectrogram.py\n",
    "\n",
    "def time_stretch(\n",
    "        spectrograms,\n",
    "        factor=1.0,\n",
    "        method=tf.image.ResizeMethod.BILINEAR):\n",
    "    \"\"\" Time stretch a spectrogram preserving shape in tensorflow. Note that\n",
    "    this is an approximation in the frequency domain.\n",
    "    :param spectrogram: Input spectrogram to be time stretched as tensor.\n",
    "    :param factor: (Optional) Time stretch factor, must be >0, default to 1.\n",
    "    :param mehtod: (Optional) Interpolation method, default to BILINEAR.\n",
    "    :returns: Time stretched spectrogram as tensor with same shape.\n",
    "    \"\"\"\n",
    "    F = tf.shape(spectrograms)[0]\n",
    "    T = tf.shape(spectrograms)[1]\n",
    "    T_ts = tf.cast(tf.cast(T, tf.float32) * factor, tf.int32)[0]  #cast: 改数据类型\n",
    "    print(T, T_ts, F)  # 7587, 6097, 513\n",
    "    ts_spec = tf.image.resize(\n",
    "        spectrograms,\n",
    "        size = [F, T_ts],\n",
    "        method=method)      # 双线性插值\n",
    "    return tf.image.resize_with_crop_or_pad(ts_spec, F, T)   # 补/切回原来形状\n",
    "\n",
    "\n",
    "def random_time_stretch(spectrogram, factor_min=0.9, factor_max=1.1, **kwargs):\n",
    "    \"\"\" Time stretch a spectrogram preserving shape with random ratio in\n",
    "    tensorflow. Applies time_stretch to spectrogram with a random ratio drawn\n",
    "    uniformly in [factor_min, factor_max].\n",
    "    :param spectrogram: Input spectrogram to be time stretched as tensor.\n",
    "    :param factor_min: (Optional) Min time stretch factor, default to 0.9.\n",
    "    :param factor_max: (Optional) Max time stretch factor, default to 1.1.\n",
    "    :returns: Randomly time stretched spectrogram as tensor with same shape.\n",
    "    \"\"\"\n",
    "    factor = tf.random.uniform(\n",
    "        shape=(1,),\n",
    "        seed=0) * (factor_max - factor_min) + factor_min\n",
    "    return time_stretch(spectrogram, factor=factor, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "频谱矩阵做random pitch shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift(\n",
    "        spectrograms,\n",
    "        semitone_shift=0.0,\n",
    "        method=tf.image.ResizeMethod.BILINEAR):\n",
    "    \"\"\" Pitch shift a spectrogram preserving shape in tensorflow. Note that\n",
    "    this is an approximation in the frequency domain.\n",
    "    :param spectrogram: Input spectrogram to be pitch shifted as tensor.\n",
    "    :param semitone_shift: (Optional) Pitch shift in semitone半音, default to 0.0.\n",
    "    :param mehtod: (Optional) Interpolation method, default to BILINEAR.\n",
    "    :returns: Pitch shifted spectrogram (same shape as spectrogram).\n",
    "    \"\"\"\n",
    "    factor = 2 ** (semitone_shift / 12.)\n",
    "    F = tf.shape(spectrograms)[0]\n",
    "    T = tf.shape(spectrograms)[1]\n",
    "    F_ps = tf.cast(tf.cast(F, tf.float32) * factor, tf.int32)[0]\n",
    "    ps_spec = tf.image.resize(\n",
    "        spectrograms,\n",
    "        [F_ps,T],\n",
    "        method=method)\n",
    "    paddings = [[0, tf.maximum(0, F - F_ps)], [0, 0], [0, 0]]\n",
    "    return tf.pad(ps_spec[:F,:,:], paddings, 'CONSTANT')\n",
    "\n",
    "\n",
    "def random_pitch_shift(spectrogram, shift_min=-1., shift_max=1., **kwargs):\n",
    "    \"\"\" Pitch shift a spectrogram preserving shape with random ratio in\n",
    "    tensorflow. Applies pitch_shift to spectrogram with a random shift\n",
    "    amount (expressed in semitones) drawn uniformly in [shift_min, shift_max].\n",
    "    :param spectrogram: Input spectrogram to be pitch shifted as tensor.\n",
    "    :param shift_min: (Optional) Min pitch shift in semitone, default to -1.\n",
    "    :param shift_max: (Optional) Max pitch shift in semitone, default to 1.\n",
    "    :returns: Randomly pitch shifted spectrogram (same shape as spectrogram).\n",
    "    \"\"\"\n",
    "    semitone_shift = tf.random.uniform(\n",
    "        shape=(1,),\n",
    "        seed=0) * (shift_max - shift_min) + shift_min\n",
    "    return pitch_shift(spectrogram, semitone_shift=semitone_shift, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandToGrid(spectrogram, time_scale, ratio_overlap):\n",
    "    # 条件： time_scale * ratio_overlap 是整数\n",
    "    K = int(ceil((spectrogram.shape[1] / time_scale - ratio_overlap)/(1-ratio_overlap)))  # ceil取上\n",
    "    newY = int(time_scale + time_scale * (1-ratio_overlap) * (K-1))\n",
    "    newX = spectrogram.shape[0]    # 行数不变\n",
    "    newSpectrogram = np.zeros((newX, newY))   # 右：多一些0，至能被girdsize整除\n",
    "    newSpectrogram[:, :spectrogram.shape[1]] = spectrogram\n",
    "    return newSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop(matrix, time_scale, ratio_overlap):\n",
    "    slices = []\n",
    "    for time in range(0, ceil((matrix.shape[1]-time_scale)/time_scale/(1-ratio_overlap))+1):   # 列\n",
    "            s = matrix[:, int(time * time_scale*(1-ratio_overlap)) :int(time * time_scale*(1-ratio_overlap)+time_scale)] # 切为很多小块，每块513*scale\n",
    "            s = np.transpose(s) # 每块大小：scale*513\n",
    "            slices.append(s)  # 存到slices列表， 使得模型的输入都一样大\n",
    "    slices_np = np.array(slices)\n",
    "    print(slices_np.shape)\n",
    "    return slices_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample rate:  44100\n",
      "spectrogram shape: (513, 7587, 1)\n",
      "each_song shape:  (513, 7587, 5)\n",
      "tf.Tensor(7587, shape=(), dtype=int32) tf.Tensor(7310, shape=(), dtype=int32) tf.Tensor(513, shape=(), dtype=int32)\n",
      "Time stretch Spectrogram shape: (513, 7587, 5)\n",
      "Pitch swift Spectrogram shape: (513, 7587, 5)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "(505, 30, 513)\n",
      "sample rate:  44100\n",
      "spectrogram shape: (513, 7244, 1)\n",
      "each_song shape:  (513, 7244, 5)\n",
      "tf.Tensor(7244, shape=(), dtype=int32) tf.Tensor(7114, shape=(), dtype=int32) tf.Tensor(513, shape=(), dtype=int32)\n",
      "Time stretch Spectrogram shape: (513, 7244, 5)\n",
      "Pitch swift Spectrogram shape: (513, 7244, 5)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n",
      "(482, 30, 513)\n"
     ]
    }
   ],
   "source": [
    "def song2spectrogram(all_path_para, fftWindowSize=1024, time_scale=30, overlap_ratio=0.5):\n",
    "    \n",
    "\n",
    "    x = np.empty((0,30,513), float)\n",
    "    x_phase = []\n",
    "    y_bass = np.empty((0,30,513), float)\n",
    "    y_drums = np.empty((0,30,513), float)\n",
    "    y_other = np.empty((0,30,513), float)\n",
    "    y_vocals = np.empty((0,30,513), float)\n",
    "    # 第0维：每首歌\n",
    "    # 第1维：height = f\n",
    "    # 第2维：width = t\n",
    "    # 第3维：每个音轨 - x,y_bass,y_drums,y_other,y_vocals 共5个\n",
    "    for key in all_path_para:   # 每首歌\n",
    "        path_list = all_path_para[key][:]\n",
    "        audio, sampleRate = loadAudioFile(path_list[0])\n",
    "        spectrogram, phase = audioFileToSpectrogram(audio, fftWindowSize)\n",
    "        each_song = np.empty([int(spectrogram.shape[0]),int(spectrogram.shape[1]),0])\n",
    "        for path in path_list:    # 每个音轨\n",
    "            audio, sampleRate = loadAudioFile(path)           \n",
    "            spectrogram, phase = audioFileToSpectrogram(audio, fftWindowSize)\n",
    "            spectrogram = spectrogram[:,:,np.newaxis]            \n",
    "            each_song = np.append(each_song, spectrogram, axis=-1)\n",
    "        print('sample rate: ',sampleRate)\n",
    "        print(\"spectrogram shape:\",spectrogram.shape)\n",
    "        print(\"each_song shape: \", each_song.shape)  # (5, 513, 7587)\n",
    "        \n",
    "        # 输入输出都做数据增强：time stretch，pitch swift\n",
    "        ts_spectrogram = random_time_stretch(each_song)   \n",
    "        print(\"Time stretch Spectrogram shape:\",ts_spectrogram.shape)\n",
    "        ps_spectrogram = random_pitch_shift(each_song)\n",
    "        print(\"Pitch swift Spectrogram shape:\",ps_spectrogram.shape)\n",
    "                \n",
    "        [hight, weidth, stem] = each_song.shape\n",
    "        for spect in [each_song, ts_spectrogram, ps_spectrogram]:\n",
    "            for i in range(stem):\n",
    "                expandedSpectrogram = expandToGrid(spect[:,:,i],time_scale,overlap_ratio)\n",
    "                slices = chop(expandedSpectrogram, time_scale,overlap_ratio)  \n",
    "                if i==0:\n",
    "                    x = np.append(x, slices,axis=0)\n",
    "                    x_phase.append(phase)\n",
    "                elif i==1:\n",
    "                    y_bass = np.append(y_bass, slices,axis=0)\n",
    "                elif i==2:\n",
    "                    y_drums = np.append(y_drums, slices,axis=0)\n",
    "                elif i==3:\n",
    "                    y_other = np.append(y_other, slices,axis=0)\n",
    "                else:   #i==4\n",
    "                    y_vocals = np.append(y_vocals, slices,axis=0)\n",
    "                \n",
    "    output = [x,x_phase,y_bass,y_drums,y_other,y_vocals]\n",
    "  \n",
    "    return output\n",
    "\n",
    "list_dataset = song2spectrogram(all_path_para=all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2961, 30, 513)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
